{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12f1749-3e2d-45e7-82c2-19b366bb6de8",
   "metadata": {},
   "source": [
    "# Optimize Your Recipe\n",
    "\n",
    "In this tutorial we will optimize the model exported in the last secion, the Application Framework [Getting Started](/af/latest/notebooks/GettingStarted/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f6ff6e-7011-4c21-98f2-097840413fe1",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "\n",
    "If you have not done so already, please ensure your environment is set up according to [Setting up your LEIP Environment](/home/content/tutorials/environment/). This will ensure that while executing this notebook the APIs of both the [Application Framework](/af/latest/content/) and [Compiler Framework](/cf/latest/content/) are accessible.\n",
    "\n",
    "First we import the necessary object definitions and initialize the connection to the leip-server.\n",
    "The code in the following cell assumes your license key was set in the `LICENSE_KEY` environment variable in the environment the notebook is run from. Alternatively it can be pasted as a string into the last parameter of the `leip.create_profile()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002e2d70-3be5-4662-baa0-b3594633cf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking connection... âœ…\n"
     ]
    }
   ],
   "source": [
    "from leip_client import (\n",
    "    Leip,\n",
    "    EvaluateTask,\n",
    "    TaskModelOptions,\n",
    "    DatasetOptions,\n",
    "    PascalVOCOptions,\n",
    "    COCOOptions,\n",
    "    CompressOptions,\n",
    "    CompileOptions,\n",
    "    PipelineTask,\n",
    "    PipelineInnerTask,\n",
    "    CompilePipelineOptions,\n",
    "    OptimizePipelineOptions,\n",
    ")\n",
    "from commons.serialization import pretty_print\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# initialize leip_client\n",
    "leip = Leip.load_instance()\n",
    "leip.create_profile(\"default\", \"http://host.docker.internal:8888\", os.environ[\"LICENSE_KEY\"])\n",
    "leip.check_connection(silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cc04b-661d-468b-9922-4c85fa9d3902",
   "metadata": {},
   "source": [
    "We will set a few variable that will be used below.\n",
    "\n",
    "The `model_folder` and `dataset_folder` should be set to match the folders where the model and dataset were saved in the last tutorial, the Application Framework [Getting Started](/af/latest/notebooks/GettingStarted/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3ed609-a3f5-4663-9711-6f8c59f4daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"/recipe_test/exported_model\"  # TODO FIXME\n",
    "dataset_folder = \"/workspace/datasets/road-sign-data\"  # TODO FIXME\n",
    "target = \"cuda\"\n",
    "target_host = \"llvm -mcpu=skylake\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755211e4-d04b-4aed-933f-7319a43f661c",
   "metadata": {},
   "source": [
    "## Optimize\n",
    "\n",
    "Next we will use the Pipeline API to group together a couple of subtasks into one batched execution. One subtask will optimize the model into `int8` for its target, and the other subtask will compile to `float32`.\n",
    "\n",
    "The optimize step requires a *representative dataset* which is used for calibration during the quantization of activations in the model. A good rule of thumb for creating a representative dataset is to include at least one image from each output class in the dataset. Often though, even a few input samples from the dataset are enough to get good quantized accuracy for the model. Other times the success of the quantization can be very sensitive to the representative dataset chosen. So you might want to experiment in this area. We will chose a simple representative dataset of 10 randomly selected images for this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2c4d57-1529-480f-a8ba-015c41582cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make rep_dataset\n",
    "rep_dataset_items = [\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000139.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000285.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000632.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000724.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000776.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000785.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000802.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000872.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000000885.jpg\",\n",
    "    \"/recipe_test/MSCocodata/validation/data/000000001000.jpg\",\n",
    "]\n",
    "rep_dataset_file = Path(\"/recipe_test/rep_dataset.txt\")\n",
    "rep_dataset_file.write_text(\"\\n\".join(rep_dataset_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ad347-7838-479d-825b-c9ee6f75b08c",
   "metadata": {},
   "source": [
    "Next we will run LEIP Pipeline. The `model_options`, `compress_options` and `compile_options` together comprise the various options needed to optimize and compile the model. Refer to the [Compiler Framework documentation](/cf/latest/content/) for more information on the available options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6ce4bc-2464-4c1b-85dc-a08519f0e48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "id        : 9\n",
      "name      : PipelineTask\n",
      "status    : completed\n",
      "options   :\n",
      "    name  : RecipePipeline\n",
      "    vars  :\n",
      "        model_path : /recipe_test/exported_model\n",
      "    tasks :\n",
      "        -\n",
      "            name     : Int8\n",
      "            optimize :\n",
      "                model    :\n",
      "                    task_family : detection\n",
      "                    path        : /recipe_test/exported_model\n",
      "                compress :\n",
      "                    quantizer   : symmetricpc\n",
      "                    rep_dataset : /recipe_test/rep_dataset.txt\n",
      "                compile  :\n",
      "                    target       : cuda -keys=cuda,gpu -arch=sm_86 -max_num_threads=1024 -thread_warp_size=32\n",
      "                    target_host  : llvm -mcpu=skylake\n",
      "                    use_tensorrt : Yes\n",
      "        -\n",
      "            name    : Float32\n",
      "            compile :\n",
      "                model        :\n",
      "                    task_family : detection\n",
      "                    path        : /recipe_test/exported_model\n",
      "                target       : cuda -keys=cuda,gpu -arch=sm_86 -max_num_threads=1024 -thread_warp_size=32\n",
      "                target_host  : llvm -mcpu=skylake\n",
      "                use_tensorrt : Yes\n",
      "results   :\n",
      "    tasks   :\n",
      "        -\n",
      "            ref     : Int8:optimize\n",
      "            success : Yes\n",
      "            value   :\n",
      "                output_path : workspace/outputs/2023-12-19-17-37-38-pipeline/Int8-optimize\n",
      "        -\n",
      "            ref     : Float32:compile\n",
      "            success : Yes\n",
      "            value   :\n",
      "                output_path : workspace/outputs/2023-12-19-17-37-38-pipeline/Float32-compile\n",
      "    success : Yes\n",
      "created   : 2023-12-19 17:37:37.901853\n",
      "updated   : 2023-12-19 17:46:41.049218\n",
      "analytics :\n"
     ]
    }
   ],
   "source": [
    "# run pipeline\n",
    "model_options = TaskModelOptions(\n",
    "    path=\"${vars.model_path}\",\n",
    "    task_family=\"detection\",\n",
    ")\n",
    "\n",
    "compress_options = CompressOptions(\n",
    "    rep_dataset=\"/recipe_test/rep_dataset.txt\",\n",
    "    quantizer=\"symmetricpc\",  # \"symmetric\", \"symmetricpc\"\n",
    "    # calibration_method=\"average\",  # \"minmax\"\n",
    "    # optimization=[\"tensor_splitting\"],\n",
    ")\n",
    "\n",
    "compile_options = compile=CompileOptions(\n",
    "    target=target,\n",
    "    target_host=target_host,\n",
    ")\n",
    "\n",
    "pipeline_config = PipelineTask(\n",
    "    vars={\n",
    "        \"model_path\": str(model_folder)\n",
    "    },\n",
    "    name=\"RecipePipeline\",\n",
    "    tasks=[\n",
    "        PipelineInnerTask(\n",
    "            name=\"Int8\",\n",
    "            optimize=OptimizePipelineOptions(\n",
    "                model=model_options,\n",
    "                compress=compress_options,\n",
    "                compile=compile_options,\n",
    "            ),\n",
    "        ),\n",
    "        PipelineInnerTask(\n",
    "            name=\"Float32\",\n",
    "            compile=CompilePipelineOptions(\n",
    "                model=model_options,\n",
    "                target=compile_options.target,\n",
    "                target_host=compile_options.target_host,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "results = pipeline_config.run()\n",
    "pretty_print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a79e34-2d96-4b1a-9580-9ade3890b799",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Now we will use the Evaluate API to run an evaluation of the optimized model on the server. This will return a mean average precision (mAP) for how well the optimized model does on the validation set of the dataset in our detection task.\n",
    "\n",
    " Refer to [the Evaluate module](/cf/3.0/content/modules/evaluate/) for more information on using LEIP Evaluate for evaluating the acurracy of a model throughout the various stages in your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff52d46-02c0-4ad1-be03-c0ccc801d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate int8\n",
    "\n",
    "dataset_options = DatasetOptions(\n",
    "    root_dir=dataset_folder,\n",
    "    voc=PascalVOCOptions(\n",
    "        data_dir=Path(\"images\"),\n",
    "        # label_map_file=Path(\"JPEGImages\"),  # TODO FIXME\n",
    "        annotations_dir=Path(\"annotations\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "evaluate_task = EvaluateTask(\n",
    "    model=TaskModelOptions(\n",
    "        path=results.results[\"tasks\"][0][\"value\"][\"output_path\"],\n",
    "        task_family=\"detection\",\n",
    "    ),\n",
    "    dataset=dataset_options,\n",
    "    # test_size=5000,\n",
    ")\n",
    "\n",
    "model_eval_job = evaluate_task.run()\n",
    "pretty_print(model_eval_job)\n",
    "mAP = model_eval_job.results[\"scoring\"][\"mAP\"][\"0.5:0.95:0.05\"]\n",
    "print(f\"int8 mAP: {mAP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35bf51-fa0d-424e-8f66-e175c04ac262",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "We have optimized our model using LEIP Optimize and evaluated how well the optimized model performs using LEIP Evaluate. We will continue with the next tutorial where we deploy the model using the [Runtime Framework](/rf/content/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
